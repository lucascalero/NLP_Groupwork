{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "219bb682",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## ExGender Bias \n",
    "__Lucas Calero Forero, Rebecca McBrayer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b4758fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6e54c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_corpus = []\n",
    "spanish_corpus = []\n",
    "french_corpus = []\n",
    "german_corpus = []\n",
    "\n",
    "for filename in os.listdir('dev'):\n",
    "    if '.en.' in filename:\n",
    "        with open(f'dev/{filename}') as f:\n",
    "            english_corpus.extend(f.readlines())\n",
    "    if '.es.' in filename:\n",
    "        with open(f'dev/{filename}') as f:\n",
    "            spanish_corpus.extend(f.readlines())\n",
    "    if '.fr.' in filename:\n",
    "        with open(f'dev/{filename}') as f:\n",
    "            french_corpus.extend(f.readlines())\n",
    "    if '.de.' in filename:\n",
    "        with open(f'dev/{filename}') as f:\n",
    "            german_corpus.extend(f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "353be6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(corpus):\n",
    "    useful = []\n",
    "    for item in corpus:\n",
    "        if len(item)> 4 and '<seg' in item:\n",
    "            start = item.find('\">')\n",
    "            end = item.find('</')\n",
    "            useful.append(item[start+3:end].lower())\n",
    "\n",
    "    # Remove punctuation\n",
    "    exclude = set(string.punctuation)\n",
    "    nopun = []\n",
    "    for st in useful:\n",
    "        st = ''.join(ch for ch in st if ch not in exclude)\n",
    "        nopun.append(st)\n",
    "\n",
    "    # Add start and ending tokens, and make all words lowercase\n",
    "    data = [sentence.split() for sentence in nopun]\n",
    "    data = list(filter(lambda a: len(a)>2, data))  # Remove blank sentences\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e989bbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_data = preprocess(english_corpus)\n",
    "spanish_data = preprocess(spanish_corpus)\n",
    "french_data = preprocess(french_corpus)\n",
    "german_data = preprocess(german_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "16807619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_articles(data, articles):\n",
    "    clean_data = []\n",
    "    for st in data:\n",
    "        st = [word for word in st if not word in articles]\n",
    "        clean_data.append(st)\n",
    "    return clean_data\n",
    "\n",
    "english_articles = ['the', 'a']\n",
    "spanish_articles = ['el', 'uno', 'la', 'un', 'una', 'los', 'las', 'unos', 'unas']\n",
    "french_articles = ['le', 'la', 'les', 'une', 'un']\n",
    "german_articles = ['der', 'die', 'das', 'dem', 'den', 'ein', 'eine', 'einer', 'einem', 'einen', 'des']\n",
    "\n",
    "english_no = remove_articles(english_data, english_articles)\n",
    "spanish_no = remove_articles(spanish_data, spanish_articles)\n",
    "french_no = remove_articles(french_data, french_articles)\n",
    "german_no = remove_articles(german_data, german_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e6a9043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_model = Word2Vec(sentences=english_data, size=200, window=7, min_count=2, workers=4, sg=1)\n",
    "spanish_model = Word2Vec(sentences=spanish_data, size=200, window=7, min_count=2, workers=4, sg=1)\n",
    "french_model = Word2Vec(sentences=french_data, size=200, window=7, min_count=2, workers=4, sg=1)\n",
    "german_model = Word2Vec(sentences=german_data, size=200, window=7, min_count=2, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7a412dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_model_no = Word2Vec(sentences=english_no, size=200, window=7, min_count=2, workers=4, sg=1)\n",
    "spanish_model_no = Word2Vec(sentences=spanish_no, size=200, window=7, min_count=2, workers=4, sg=1)\n",
    "french_model_no = Word2Vec(sentences=french_no, size=200, window=7, min_count=2, workers=4, sg=1)\n",
    "german_model_no = Word2Vec(sentences=german_no, size=200, window=7, min_count=2, workers=4, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "10389cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 17439\n",
      "Spanish vocab size: 21096\n",
      "French vocab size: 22095\n",
      "German vocab size: 26759\n"
     ]
    }
   ],
   "source": [
    "print(f'English vocab size: {len(english_model.wv.vocab)}')\n",
    "print(f'Spanish vocab size: {len(spanish_model.wv.vocab)}')\n",
    "print(f'French vocab size: {len(french_model.wv.vocab)}')\n",
    "print(f'German vocab size: {len(german_model.wv.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "29ef77e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English no article vocab size: 17437\n",
      "Spanish no article vocab size: 21087\n",
      "French no article vocab size: 22090\n",
      "German no article vocab size: 26749\n"
     ]
    }
   ],
   "source": [
    "print(f'English no article vocab size: {len(english_model_no.wv.vocab)}')\n",
    "print(f'Spanish no article vocab size: {len(spanish_model_no.wv.vocab)}')\n",
    "print(f'French no article vocab size: {len(french_model_no.wv.vocab)}')\n",
    "print(f'German no article vocab size: {len(german_model_no.wv.vocab)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e55fc398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6760016\n",
      "0.86425006\n",
      "0.63809365\n",
      "0.8240618\n"
     ]
    }
   ],
   "source": [
    "print(english_model.wv.similarity('men', 'model'))\n",
    "print(english_model.wv.similarity('women', 'model'))\n",
    "print(english_model_no.wv.similarity('men', 'model'))\n",
    "print(english_model_no.wv.similarity('women', 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a36cb664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95374393\n",
      "0.83905363\n",
      "0.9221438\n",
      "0.83946764\n"
     ]
    }
   ],
   "source": [
    "print(spanish_model.wv.similarity('señor','modelo'))\n",
    "print(spanish_model.wv.similarity('señora','modelo')) # masculine\n",
    "print(spanish_model_no.wv.similarity('señor','modelo'))\n",
    "print(spanish_model_no.wv.similarity('señora','modelo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a086f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.59201884\n",
      "0.76704276\n",
      "0.688988\n",
      "0.81426114\n"
     ]
    }
   ],
   "source": [
    "print(french_model.wv.similarity('hommes', 'modèle'))\n",
    "print(french_model.wv.similarity('femmes', 'modèle'))  # feminine\n",
    "print(french_model_no.wv.similarity('hommes', 'modèle'))\n",
    "print(french_model_no.wv.similarity('femmes', 'modèle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "405c08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981342\n",
      "0.7479851\n",
      "0.86717266\n",
      "0.83772045\n"
     ]
    }
   ],
   "source": [
    "print(german_model.wv.similarity('männer', 'model'))\n",
    "print(german_model.wv.similarity('frauen', 'model')) # neutral\n",
    "print(german_model_no.wv.similarity('männer', 'model'))\n",
    "print(german_model_no.wv.similarity('frauen', 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845f5ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
